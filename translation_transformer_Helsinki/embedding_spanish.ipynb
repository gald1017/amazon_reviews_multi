{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727f0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1497c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok(tokenizer, text):\n",
    "    return tokenizer.encode_plus(text, \n",
    "                                    add_special_tokens=True,\n",
    "                                    max_length=510,\n",
    "                                    padding='longest', \n",
    "                                    truncation=True,\n",
    "                                      return_token_type_ids=True,\n",
    "                                      return_attention_mask=True,\n",
    "                                      return_tensors='pt'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b4eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_embed(df, model, tokenizer):\n",
    "    l = []\n",
    "    for i, review in enumerate(df.review_body):\n",
    "        tokened = tok(tokenizer, review)\n",
    "        #print(model(**tokenizer))\n",
    "        l.append(embed(model_mul, tokened).numpy())\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fc8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Tuple\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import torch\n",
    "\n",
    "def embed(model, tokens_tensor ):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        model.to('cuda')\n",
    "        outputs = model(**tokens_tensor)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        # Stores the token vectors, with shape [6 x 768]\n",
    "    \n",
    "    token_vecs_sum = []\n",
    "\n",
    "    # `token_embeddings` is a [6 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [6 x 768] tensor\n",
    "\n",
    "        # Sum the vectors from the last four layers.\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "\n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "        \n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all 6 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return sentence_embedding\n",
    "\n",
    "def embed_cls(model, tokens_tensor):\n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tokens_tensor = tokens_tensor.to('cuda')       \n",
    "        model.to('cuda')\n",
    "        \n",
    "        #if torch.cuda.device_count() > 1:\n",
    "            #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            #model = nn.DataParallel(model)\n",
    "        #else:\n",
    "            #model.to(device)\n",
    "        \n",
    "        outputs = model(**tokens_tensor)\n",
    "        \n",
    "        return outputs.pooler_output\n",
    "        \n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_tokenizer,\n",
    "            bert_model,\n",
    "            max_length: int = 510,\n",
    "            embedding_func = None,\n",
    "    ):\n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.model = bert_model\n",
    "        self.model.eval()\n",
    "        self.max_length = max_length\n",
    "        self.embedding_func = embedding_func\n",
    "\n",
    "        if self.embedding_func is None:\n",
    "            self.embedding_func = lambda x: x[0][:, 0, :].squeeze()\n",
    "\n",
    "    def _tokenize(self, text: str) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        # Tokenize the text with the provided tokenizer\n",
    "#         tokenized_text = self.tokenizer.encode_plus(text,\n",
    "#                                                     add_special_tokens=True,\n",
    "#                                                     max_length=self.max_length\n",
    "#                                                     )[\"input_ids\"]\n",
    "        \n",
    "        tokenized_text = self.tokenizer.encode_plus(text, \n",
    "                                    add_special_tokens=True,\n",
    "                                    max_length=self.max_length,\n",
    "                                    padding='longest', \n",
    "                                    truncation=True,\n",
    "                                    return_token_type_ids=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_tensors='pt'\n",
    "                                    )\n",
    "        return tokenized_text\n",
    "\n",
    "\n",
    "    def _tokenize_and_predict(self, text: str) -> torch.tensor:\n",
    "        tokenized = self._tokenize(text)\n",
    "\n",
    "        #embeddings = self.model(**tokenized)\n",
    "        return self.embedding_func(self.model, tokenized)\n",
    "\n",
    "    def transform(self, text: List[str]):\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "        \n",
    "#         return torch.stack([self._tokenize_and_predict(string) for string in text]).cpu()\n",
    "\n",
    "        return torch.stack([self._tokenize_and_predict(text)]).cpu()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"No fitting necessary so we just return ourselves\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc023f3c",
   "metadata": {},
   "source": [
    "# Data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb379401",
   "metadata": {},
   "source": [
    "### English dataset tranlated to spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea4f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_to_es_train = torch.load('amz_train_en_to_es_Translation_Helsinki.pkl')\n",
    "eng_to_es_test = torch.load('amz_test_en_to_es_Translation_Helsinki.pkl')\n",
    "eng_to_es_val = torch.load('amz_val_en_to_es_Translation_Helsinki.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fa673",
   "metadata": {},
   "source": [
    "### Spanish -original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "227f9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_train = pd.read_csv('../data/train_es').review_body\n",
    "es_test = pd.read_csv('../data/test_es').review_body\n",
    "es_val = pd.read_csv('../data/val_es').review_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc8ca1",
   "metadata": {},
   "source": [
    "# LABSE BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "426e3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_mul = BertTokenizer.from_pretrained(\"pvl/labse_bert\")\n",
    "model_mul = BertModel.from_pretrained('pvl/labse_bert',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e42c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert_transformer = BertTransformer(tokenizer_mul, model_mul, embedding_func=embed)\n",
    "bert_transformer = BertTransformer(tokenizer_mul, model_mul, embedding_func=embed_cls)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2d6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.027315855026245\n",
      "41.09771680831909\n",
      "37.729169607162476\n",
      "37.7992742061615\n",
      "1506.2099006175995\n",
      "1509.6874799728394\n",
      "37.675663232803345\n",
      "37.746981382369995\n",
      "37.727787017822266\n",
      "37.7990984916687\n",
      "1512.413660287857\n",
      "1515.9639060497284\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "\n",
    "texts = [es_val, es_test, es_train, eng_to_es_val, eng_to_es_test, eng_to_es_train ]\n",
    "files_name = ['es_val_labse_embdded.pkl', 'es_test_labse_embdded.pkl', 'es_train_labse_embdded.pkl', 'eng_to_es_val_labse_embdded.pkl', 'eng_to_es_test_labse_embdded.pkl', 'eng_to_es_train_labse_embdded.pkl' ]\n",
    "\n",
    "\n",
    "for i,t in enumerate(texts):\n",
    "    emebedded = []\n",
    "    start = time.time()\n",
    "    for k,com in enumerate(t):\n",
    "        emebedded.append(bert_transformer.transform(com))\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    \n",
    "    with open(files_name[i], 'wb') as f:\n",
    "        torch.save(list(itertools.chain(*emebedded)), f)    \n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ebfd3",
   "metadata": {},
   "source": [
    "# Spanish BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0f8cd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f4252cca714839ab859df8e916c3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/174k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30a3b560ec64d84b96239847d4e0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb807fa24d1d4f06add8bcbf114e5070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46165082010b41aca33ffcdae428d852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/425M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Geotrend/bert-base-es-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_mul = BertTokenizer.from_pretrained(\"Geotrend/bert-base-es-cased\")\n",
    "model_mul = BertModel.from_pretrained(\"Geotrend/bert-base-es-cased\",\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee26aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_transformer = BertTransformer(tokenizer_mul, model_mul, embedding_func=embed_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e8501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.54897403717041\n",
      "37.621267557144165\n",
      "37.43864393234253\n",
      "37.51006722450256\n",
      "1661.582781791687\n",
      "1664.9422955513\n",
      "37.30940222740173\n",
      "37.38084363937378\n",
      "37.23605251312256\n",
      "37.309192180633545\n",
      "1502.438512802124\n",
      "1505.7900450229645\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "\n",
    "texts = [es_val, es_test, es_train, eng_to_es_val,eng_to_es_test, eng_to_es_train ]\n",
    "files_name = ['es_val_bert-base-es-cased_embdded.pkl', 'es_test_bert-base-es-cased_embdded.pkl', 'es_train_bert-base-es-cased_embdded.pkl', 'eng_to_es_val_bert-base-es-cased_embdded.pkl', 'eng_to_es_test_bert-base-es-cased_embdded.pkl', 'eng_to_es_train_bert-base-es-cased_embdded.pkl' ]\n",
    "\n",
    "\n",
    "for i,t in enumerate(texts):\n",
    "    emebedded = []\n",
    "    start = time.time()\n",
    "    for k,com in enumerate(t):\n",
    "        emebedded.append(bert_transformer.transform(com))\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    \n",
    "    with open(files_name[i], 'wb') as f:\n",
    "        torch.save(list(itertools.chain(*emebedded)), f)    \n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f570d8",
   "metadata": {},
   "source": [
    "# BETO BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73aa4559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c9839bc839465ebe468216c753dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2651999cda4c30a7ead6083952f8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595a9be2fa8e4d38965b7dd29e91c8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/253 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a1700f90134a318f76474aabd84fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34d19c1cfa142049927054111b89e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_mul = BertTokenizer.from_pretrained(\"finiteautomata/beto-sentiment-analysis\")\n",
    "model_mul = BertModel.from_pretrained(\"finiteautomata/beto-sentiment-analysis\",\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c3e6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_transformer = BertTransformer(tokenizer_mul, model_mul, embedding_func=embed_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e48d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.18480849266052\n",
      "37.25659394264221\n",
      "37.0012092590332\n",
      "37.07319140434265\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "\n",
    "texts = [es_val, es_test, es_train, eng_to_es_val,eng_to_es_test, eng_to_es_train ]\n",
    "files_name = ['es_val_beto_embdded.pkl', 'es_test_beto_embdded.pkl', 'es_train_beto_embdded.pkl', 'eng_to_es_val_bbeto_embdded.pkl', 'eng_to_es_test_beto_embdded.pkl', 'eng_to_es_train_beto_embdded.pkl' ]\n",
    "\n",
    "\n",
    "for i,t in enumerate(texts):\n",
    "    emebedded = []\n",
    "    start = time.time()\n",
    "    for k,com in enumerate(t):\n",
    "        emebedded.append(bert_transformer.transform(com))\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    \n",
    "    with open(files_name[i], 'wb') as f:\n",
    "        torch.save(list(itertools.chain(*emebedded)), f)    \n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80668c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
